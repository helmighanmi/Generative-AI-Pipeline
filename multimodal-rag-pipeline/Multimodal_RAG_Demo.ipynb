{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal RAG Demo\n",
    "This notebook demonstrates the full pipeline: PDF ingestion â†’ embeddings â†’ FAISS â†’ retrieval â†’ generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import Config\n",
    "from src.embedding import EmbeddingService\n",
    "from src.generator import GeneratorService\n",
    "from src.vectorstore import FaissVectorStore\n",
    "from src.rag import retrieve, rag_ask\n",
    "from src.data_processing import download_pdf, create_directories, process_text_chunks, process_tables, process_images, process_page_images\n",
    "import pymupdf\n",
    "from tqdm import tqdm\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "embedder = EmbeddingService()\n",
    "generator = GeneratorService()\n",
    "print('Embedding provider:', config.get_embedding_provider())\n",
    "print('LLM provider:', config.get_llm_provider())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = config.get_data_paths()\n",
    "pdf_url = 'https://arxiv.org/pdf/1706.03762.pdf'\n",
    "filename = 'attention.pdf'\n",
    "filepath = download_pdf(pdf_url, paths['input_dir'], filename)\n",
    "create_directories(paths['output_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pymupdf.open(filepath)\n",
    "items = []\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=config.get_pipeline_config()['chunk_size'], chunk_overlap=config.get_pipeline_config()['chunk_overlap'])\n",
    "for page_num,page in enumerate(doc):\n",
    "    text = page.get_text()\n",
    "    if text.strip(): process_text_chunks(filepath,text,splitter,page_num,paths['output_dir'],items)\n",
    "    process_tables(filepath,doc,page_num,paths['output_dir'],items)\n",
    "    process_images(doc,page,page_num,paths['output_dir'],items)\n",
    "    process_page_images(page,page_num,paths['output_dir'],items)\n",
    "print('Extracted',len(items),'items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=[]\n",
    "with tqdm(total=len(items),desc='Embedding items') as bar:\n",
    "    for it in items:\n",
    "        if it['type']=='text': emb=embedder.embed(text=it['text'])\n",
    "        elif it['type'] in ['image','page']: emb=embedder.embed(image_b64=it['image'])\n",
    "        else: emb=None\n",
    "        it['embedding']=emb; embeddings.append(emb); bar.update(1)\n",
    "vs_cfg=config.get_vectorstore_config()\n",
    "store=FaissVectorStore(index_path=vs_cfg['index_path'],metadata_path=vs_cfg['metadata_path'])\n",
    "store.build(embeddings,items); store.save(); store.load()\n",
    "print('âœ… Index built and loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=retrieve(store,'Which optimizer was used for training?',top_k=3)\n",
    "for r in results:\n",
    "    print(f\"Page {r['page']} ({r['type']})\")\n",
    "    if 'text' in r: print(r['text'][:300])\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=rag_ask(store,'Which optimizer was used for training?',top_k=3)\n",
    "print('ðŸ¤– Answer:\\n',answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
